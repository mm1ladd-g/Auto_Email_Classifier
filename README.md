# ðŸ“§Â AutoÂ EmailÂ ClassifierÂ ðŸš€

[![CI](https://github.com/mm1ladd-g/Auto_Email_Classifier/actions/workflows/ci.yml/badge.svg)](https://github.com/mm1ladd-g/Auto_Email_Classifier/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/mm1ladd-g/Auto_Email_Classifier/branch/main/graph/badge.svg)](https://codecov.io/gh/mm1ladd-g/Auto_Email_Classifier)
[![ruff](https://img.shields.io/badge/codeâ€‘styleâ€‘ruff-%2314b?logo=python&logoColor=white)](https://github.com/astralâ€‘sh/ruff)

> **Oneâ€‘click microâ€‘service that autoâ€‘routes incoming eâ€‘mails into four businessâ€‘critical buckets**
> `supportâ€‚|â€‚salesâ€‚|â€‚partnershipâ€‚|â€‚spamâ€‚(+ unknown for lowâ€‘confidence)`

Optimised for **reproducibility**, **MLOps hygiene** and **Appleâ€‘Silicon performance**.
Total build time â‰ˆÂ 14Â h (including weakâ€‘labelling & fineâ€‘tune).

---

## TableÂ ofÂ Contents

1. [Features](#features)
2. [QuickÂ Start](#quick-start)
3. [Configuration](#configuration)
4. [Dataset &amp;Â Modelling](#dataset--modelling)
5. [APIÂ Reference](#api-reference)
6. [Testing &amp;Â CI](#testing--ci)
7. [Deployment](#deployment)
8. [Security &amp;Â Robustness](#security--robustness)
9. [Roadmap](#roadmap)
10. [License &amp;Â Credits](#license--credits)

---

## Features

* **Quantised MiniLM (INTâ€‘8 ONNX)** â€“ 20Â ms / eâ€‘mail on 1Â vCPU.
* **Weakâ€‘labelled EnronÂ + spam corpus** (170Â k mails) with keyword precedence.
* **ConfidenceÂ gating** â€“ returns `"unknown"` below threshold.
* **Dockerâ€‘first**: multiâ€‘arch image (arm64 &Â x86â€‘64) <Â 260Â MB.
* **97Â % test coverage**, `ruff`Â +Â `black` formatting, `mypy --strict` typing.
* **Singleâ€‘command retrain/export** via Makefile.

---

## QuickÂ Start

###Â Prerequisites

* PythonÂ 3.11
* (optional)Â DockerÂ â‰¥Â 24
* (optional)Â DVCÂ â‰¥Â 3 for lazy data/model pulls

###Â LocalÂ dev

```bash
git clone https://github.com/mm1ladd-g/Auto_Email_Classifier.git
cd Auto_Email_Classifier

python -m venv .venv && source .venv/bin/activate
pip install --upgrade pip wheel
pip install -r requirements-lock.txt

# pull processed data & models (â‰ˆÂ 180Â MB), or run pipelines yourself
dvc pull

uvicorn app.main:app --reload            # http://127.0.0.1:8000/docs
```

### Docker

docker build -t email-classifier:latest .
docker run -p 8000:8000 email-classifier:latest
curl -X POST localhost:8000/predict
    -H "Content-Type: application/json"
    -d '{"email":"Need help with my invoice"}' | jq

## Configuration

All tunables are exposed via environment variables (defaults in parentheses):

Variable | Description
ONNX_MODEL_PATHÂ (models/minilm-int8.onnx) | Path to model artefact
TOKENIZER_DIRÂ (models/minilm-epoch3) | HuggingÂ Face tokenizer dir
AEC_MAX_EMAIL_BYTESÂ (4096) | Max input size â€“ requests above are 413
AEC_CONFIDENCE_THRESHOLDÂ (0.50) | Below â†’ label set toÂ unknown

## Dataset & Modelling

### Corpus overview

Source | Rows after weakâ€‘labelling | License
Enron (KaggleÂ acsariyildiz/â€¦) | 136Â k | Public domain
Multiple spam CSVs | Â 33Â k | CCÂ BYâ€‘NCâ€‘NDÂ 4.0
Synthetic (GPTâ€‘4 fewâ€‘shot) | Â 2Â k | MIT

### Modelling pipeline

Stage | Tooling | ValÂ Accuracy | ValÂ Macroâ€‘F1
BaselineÂ (TFâ€‘IDFÂ +Â MultinomialNB) | scikitâ€‘learn | Â 0.806 | Â 0.468
Fineâ€‘tuned MiniLMÂ (3Â epochs) | HFÂ TransformersÂ +Â PyTorchÂ Lightning | 0.890 Â±Â 0.01 | 0.73 Â±Â 0.01

Weights exported to 8â€‘bit ONNX ( **60 MB** ).

Reproduce locally:

# build dataset

python src/data/build_dataset.py

# baseline

python src/pipelines/baseline.py

# fineâ€‘tune MiniLM (AppleÂ Silicon GPU â‡’ add --accelerator='gpu')

python src/pipelines/minilm_finetune.py

# export & quantise

python src/pipelines/export_onnx.py

API Reference

Method | Path | ReqÂ Body | RespÂ 200
GET | /healthz | â€“ | { "status": "ok" }
POST | /predict | { "email": "textâ€¦" } | { "category": "support", "probabilities": { â€¦ } }

Lowâ€‘confidence outputs return** **`"unknown"` as** **`category`.

Testing & CI

make lint         # ruff, blackÂ --check, mypyÂ --strict
make test         # pytest + coverage

GitHub Actions runs the full matrix ( **linux / macOS** , 3.11, arm64 & x86â€‘64) and uploads coverage to Codecov.

## Deployment


### Container

* Two Uvicorn workers (`--workers 2`) maximise QPS on a single vCPU.
* `HEALTHCHECK` hits** **`/healthz`; container starts with** **`--lifespan on` so FastAPI only reports â€œhealthyâ€ after the model is loaded.

### Kubernetes (optional)


kubectl apply -f docker/k8s.yaml    # includes HPAÂ (cpuâ€‘based)


## Security & Robustness

* **Strict Pydantic schemas** â€“ unknown JSON keys are rejected (`400`).
* **Size guard** â€“ requests over 4 kB â†’** **`413 Payload Too Large`.
* **Pinned deps** â€“** **`requirements-lock.txt`.
* **Readonly filesystem** â€“ container runs as nonâ€‘root, FS mounted** **`ro` by default.
* **Confidence gating** â€“ prevents wrong autoâ€‘routing when the model is unsure.


## Roadmap

* [ ] Activeâ€‘learning loop with humanâ€inâ€‘theâ€‘loop UI
* [ ] `/explain` endpoint (SHAP) for perâ€‘email transparency
* [ ] Metal f16 fineâ€‘tune to halve latency on Mâ€‘series chips



## License & Credits

Code & synthetic data Â© 2025 Milad Ghavampoori â€“ MIT License.

Enron corpus is public domain; spam CSVs under CC BYâ€‘NCâ€‘ND 4.0.

Big shoutâ€‘out to the OSS community: Hugging Face, FastAPI, DVC, ONNX Runtime â¤ï¸
